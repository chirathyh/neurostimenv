import os
import numpy as np
import neuron
from LFPy import Network
from neuron import units
import h5py


def flattenlist(lst):
    return [item for sublist in lst for item in sublist]

def ReduceStructArray(sendbuf):
    """
    simplify MPI Reduce for structured ndarrays with floating point numbers

    Parameters
    ----------
    sendbuf: structured ndarray
        Array data to be reduced (default: summed)

    Returns
    -------
    recvbuf: structured ndarray or None
        Reduced array on RANK 0, None on all other RANKs
    """
    pc = neuron.h.ParallelContext()
    RANK = pc.id()

    if RANK == 0:
        shape = sendbuf.shape
        dtype_names = sendbuf.dtype.names
    else:
        shape = None
        dtype_names = None
    shape = pc.py_broadcast(shape, 0)
    dtype_names = pc.py_broadcast(dtype_names, 0)

    if RANK == 0:
        reduced = np.zeros(shape,
                           dtype=list(zip(dtype_names,
                                          ['f8' for i in range(len(dtype_names)
                                                               )])))
    else:
        reduced = None
    for name in dtype_names:
        recvbuf = neuron.h.Vector(sendbuf[name].flatten())
        pc.allreduce(recvbuf, 1)
        if RANK == 0:
            reduced[name] = np.array(recvbuf).reshape(shape)
    return reduced

class DummyCell(object):
    def __init__(self, totnsegs=0,
                 x=None,
                 y=None,
                 z=None,
                 d=None,
                 area=None,
                 length=None,
                 somainds=None):
        """
        Dummy Cell object initialized with all attributes needed for LFP
        calculations using the LFPy.RecExtElectrode class and methods.
        This cell can be imagined as one "super" cell containing transmembrane
        currents generated by all NetworkCell segments on this RANK at once.

        Parameters
        ----------
        totnsegs: int
            total number of segments
        x, y, z: ndarray
            arrays of shape (totnsegs, 2) with (x,y,z) coordinates of start
            and end points of segments in units of (um)
        d: ndarray
            array of length totnsegs with segment diameters
        area: ndarray
            array of segment surface areas
        length: ndarray
            array of segment lengths
        """
        # set attributes
        self.totnsegs = totnsegs
        self.x = x if x is not None else np.array([])
        self.y = y if y is not None else np.array([])
        self.z = z if z is not None else np.array([])
        self.d = d if d is not None else np.array([])
        self.area = area if area is not None else np.array([])
        self.length = length if area is not None else np.array([])
        self.somainds = somainds if somainds is not None else np.array([])

    def get_idx(self, section="soma"):
        if section == "soma":
            return self.somainds
        else:
            raise ValueError('section argument must be "soma"')


class NetworkEnv(Network):
    def __int__(self, **networkParameters):
        super().__init__(**networkParameters)

    def init_simulation(self, probes=None, rl_args=None,
                 rec_imem=False, rec_vmem=False,
                 rec_ipas=False, rec_icap=False,
                 rec_isyn=False, rec_vmemsyn=False, rec_istim=False,
                 rec_pop_contributions=False,
                 rec_variables=[], variable_dt=False, atol=0.001,
                 to_memory=True, to_file=False,
                 file_name='OUTPUT.h5',
                 **kwargs):
        """
        This is the main function running the simulation of the network model.

        Parameters
        ----------
        probes: list of :obj:, optional
            None or list of LFPykit.RecExtElectrode like object instances that
            each have a public method `get_transformation_matrix` returning
            a matrix that linearly maps each segments' transmembrane
            current to corresponding measurement as

            .. math:: \\mathbf{P} = \\mathbf{M} \\mathbf{I}

        rec_imem: bool
            If true, segment membrane currents will be recorded
            If no electrode argument is given, it is necessary to
            set rec_imem=True in order to calculate LFP later on.
            Units of (nA).
        rec_vmem: bool
            record segment membrane voltages (mV)
        rec_ipas: bool
            record passive segment membrane currents (nA)
        rec_icap: bool
            record capacitive segment membrane currents (nA)
        rec_isyn: bool
            record synaptic currents of from Synapse class (nA)
        rec_vmemsyn: bool
            record membrane voltage of segments with Synapse (mV)
        rec_istim: bool
            record currents of StimIntraElectrode (nA)
        rec_pop_contributions: bool
            If True, compute and return single-population contributions to
            the extracellular potential during simulation time
        rec_variables: list of str
            variables to record, i.e arg=['cai', ]
        variable_dt: boolean
            use variable timestep in NEURON. Can not be combimed with `to_file`
        atol: float
            absolute tolerance used with NEURON variable timestep
        to_memory: bool
            Simulate to memory. Only valid with `probes=[<probe>, ...]`, which
            store measurements to -> <probe>.data
        to_file: bool
            only valid with `probes=[<probe>, ...]`, saves measurement in
            hdf5 file format.
        file_name: str
            If to_file is True, file which measurements will be
            written to. The file format is HDF5, default is "OUTPUT.h5", put
            in folder Network.OUTPUTPATH
        **kwargs:  keyword argument dict values passed along to function
                    `__run_simulation_with_probes()`, containing some or all of
                    the boolean flags: `use_ipas`, `use_icap`, `use_isyn`
                    (defaulting to `False`).

        Returns
        -------
        events
            Dictionary with keys `times` and `gids`, where values are
            ndarrays with detected spikes and global neuron identifiers

        Raises
        ------
        Exception
            if `CVode().use_fast_imem()` method not found
        AssertionError
            if rec_pop_contributions==True and probes==None
        """
        # set up integrator, use the CVode().fast_imem method by default
        # as it doesn't hurt sim speeds much if at all.

        self.obs_win_len = rl_args.obs_win_len

        cvode = neuron.h.CVode()
        try:
            cvode.use_fast_imem(1)
        except AttributeError:
            raise Exception('neuron.h.CVode().use_fast_imem() not found. '
                            'Please update NEURON to v.7.4 or newer')

        # test some of the inputs
        if probes is None:
            assert rec_pop_contributions is False, \
                'rec_pop_contributions can not be True when probes is None'

        if not variable_dt:
            dt = self.dt
        else:
            dt = None

        for name in self.population_names:
            for cell in self.populations[name].cells:
                cell._set_soma_volt_recorder(dt)
                if rec_imem:
                    cell._set_imem_recorders(dt)
                if rec_vmem:
                    cell._set_voltage_recorders(dt)
                if rec_ipas:
                    cell._set_ipas_recorders(dt)
                if rec_icap:
                    cell._set_icap_recorders(dt)
                if len(rec_variables) > 0:
                    cell._set_variable_recorders(rec_variables)

        ####
        # Initialize NEURON simulations of cell object
        neuron.h.dt = self.dt

        # needed for variable dt method
        if variable_dt:
            cvode.active(1)
            cvode.atol(atol)
        else:
            cvode.active(0)

        # initialize state
        neuron.h.finitialize(self.v_init * units.mV)

        # use fast calculation of transmembrane currents
        cvode.use_fast_imem(1)

        # initialize current- and record
        if cvode.active():
            cvode.re_init()
        else:
            neuron.h.fcurrent()
        neuron.h.frecord_init()

        # Starting simulation at tstart
        neuron.h.t = self.tstart
        ####

        # self.step(
        #         probes=probes,
        #         to_memory=to_memory,
        #         to_file=to_file,
        #         file_name='tmp_output_RANK_{:03d}.h5',
        #         rec_pop_contributions=rec_pop_contributions,
        #         **kwargs)

        # for name in self.population_names:
        #     for cell in self.populations[name].cells:
        #         # somatic trace
        #         cell.somav = np.array(cell.somav)
        #         if rec_imem:
        #             cell._calc_imem()
        #         if rec_ipas:
        #             cell._calc_ipas()
        #         if rec_icap:
        #             cell._calc_icap()
        #         if rec_vmem:
        #             cell._collect_vmem()
        #         if rec_isyn:
        #             cell._collect_isyn()
        #         if rec_vmemsyn:
        #             cell._collect_vsyn()
        #         if rec_istim:
        #             cell._collect_istim()
        #         if len(rec_variables) > 0:
        #             cell._collect_rec_variables(rec_variables)
        #         if hasattr(cell, '_hoc_netstimlist'):
        #             del cell._hoc_netstimlist
        #
        # # Collect spike trains across all RANKs to RANK 0
        # for name in self.population_names:
        #     population = self.populations[name]
        #     population.spike_vectors = []
        #     for i in range(len(population._hoc_spike_vectors)):
        #         population.spike_vectors += \
        #             [population._hoc_spike_vectors[i].as_numpy()]
        #
        # # collect spike times to RANK 0
        # if self._RANK == 0:
        #     times = []
        #     gids = []
        # else:
        #     times = None
        #     gids = None
        # for i, name in enumerate(self.population_names):
        #     times_send = [x for x in self.populations[name].spike_vectors]
        #     gids_send = [x for x in self.populations[name].gids]
        #     if self._RANK == 0:
        #         times.append([])
        #         gids.append([])
        #         times[i] += flattenlist(self.pc.py_gather(times_send))
        #         gids[i] += flattenlist(self.pc.py_gather(gids_send))
        #
        #         assert len(times[-1]) == len(gids[-1])
        #     else:
        #         _ = self.pc.py_gather(times_send)
        #         _ = self.pc.py_gather(gids_send)
        #
        # # create final output file, summing up single RANK output from
        # # temporary files
        # if to_file and probes is not None:
        #     # op = MPI.SUM
        #     fname = os.path.join(
        #         self.OUTPUTPATH,
        #         'tmp_output_RANK_{:03d}.h5'.format(
        #             self._RANK))
        #     f0 = h5py.File(fname, 'r')
        #     if self._RANK == 0:
        #         f1 = h5py.File(os.path.join(self.OUTPUTPATH, file_name), 'w')
        #     dtype = []
        #     for key, value in f0[list(f0.keys())[0]].items():
        #         dtype.append((str(key), float))
        #     for grp in f0.keys():
        #         if self._RANK == 0:
        #             # get shape from the first dataset
        #             # (they should all be equal):
        #             for value in f0[grp].values():
        #                 shape = value.shape
        #                 continue
        #             f1[grp] = np.zeros(shape, dtype=dtype)
        #         for key, value in f0[grp].items():
        #             recvbuf = neuron.h.Vector(
        #                 value[()].astype(float).flatten())
        #             self.pc.allreduce(recvbuf, 1)
        #             if self._RANK == 0:
        #                 f1[grp][key] = np.array(recvbuf).reshape(value.shape)
        #             else:
        #                 recvbuf = None
        #     f0.close()
        #     if self._RANK == 0:
        #         f1.close()
        #     os.remove(fname)
        #
        # if probes is not None:
        #     if to_memory:
        #         # communicate and sum up measurements on each probe before
        #         # returing spike times and corresponding gids:
        #         for probe in probes:
        #             probe.data = ReduceStructArray(probe.data)
        #
        # return dict(times=times, gids=gids)

    def step(self, probes=None,rec_imem= False,rec_vmem= False,rec_ipas= False,rec_icap= False,
                                    rec_isyn= False,
                                       rec_vmemsyn= False,
                                       rec_istim= False,
                                    rec_current_dipole_moment=False,
                                    rec_variables= [],
                                    dotprodcoeffs= None,
                                     to_memory=True,
                                     to_file=False,
                                     file_name=None,
                                     use_ipas=False, use_icap=False,
                                     use_isyn=False,
                                     rec_pop_contributions=False
                                     ):
        """
        Running the actual simulation in NEURON with list of probes.
        Each object in `probes` must have a public method
        `get_transformation_matrix` which returns a linear mapping of
        transmembrane currents to corresponding measurement.

        Parameters
        ----------
        cvode: neuron.h.CVode() object
        probes: list of :obj:, optional
            None or list of LFPykit.RecExtElectrode like object instances that
            each have a public method `get_transformation_matrix` returning
            a matrix that linearly maps each segments' transmembrane
            current to corresponding measurement as

            .. math:: \\mathbf{P} = \\mathbf{M} \\mathbf{I}

        variable_dt: bool
            switch for variable-timestep method
        atol: float
            absolute tolerance with CVode for variable time-step method
        rtol: float
            relative tolerance with CVode for variable time-step method
        to_memory: bool
            Boolean flag for computing extracellular potentials,
            default is True.
            If True, the corresponding <probe>.data attribute will be set.
        to_file: bool or None
            Boolean flag for computing extracellular potentials to file
            <OUTPUTPATH/file_name>, default is False. Raises an Exception if
            `to_memory` is True.
        file_name: formattable str
            If to_file is True, file which extracellular potentials will be
            written to. The file format is HDF5, default is
            "output_RANK_{:03d}.h5". The output is written per RANK, and the
            RANK # will be inserted into the corresponding file name.
        use_ipas: bool
            if True, compute the contribution to extracellular potentials
            across the passive leak channels embedded in the cells membranes
            summed over populations
        use_icap: bool
            if True, compute the contribution to extracellular potentials
            across the membrane capacitance embedded in the cells membranes
            summed over populations
        use_isyn: bool
            if True, compute the contribution to extracellular potentials
            across the excitatory and inhibitory synapses embedded in the cells
            membranes summed over populations
        rec_pop_contributions: bool
            if True, compute and return single-population contributions to the
            extracellular potential during each time step of the simulation

        Returns
        -------

        Raises
        ------
        Exception:
        - `if to_memory == to_file == True`
        - `if to_file == True and file_name is None`
        - `if to_file == variable_dt == True`
        - `if <probe>.cell is not None`
        """

        tstep = 0
        mini_step_time = self.obs_win_len #100  # 2000

        if to_memory and to_file:
            raise Exception('to_memory and to_file can not both be True')
        if to_file and file_name is None:
            raise Exception
        # create a dummycell object lumping together needed attributes
        # for calculation of extracellular potentials etc. The population_nsegs
        # array is used to slice indices such that single-population
        # contributions to the potential can be calculated.
        population_nsegs, network_dummycell = self._Network__create_network_dummycell()

        # set cell attribute on each probe, assuming that each probe was
        # instantiated with argument cell=None
        for probe in probes:
            if probe.cell is None:
                probe.cell = network_dummycell
            else:
                raise Exception('{}.cell!=None'.format(probe.__class__))

        # create list of transformation matrices; one for each probe
        transforms = []
        if probes is not None:
            for probe in probes:
                transforms.append(probe.get_transformation_matrix())

        # reset probe.cell to None, as it is no longer needed
        for probe in probes:
            probe.cell = None

        # set maximum integration step, it is necessary for communication of
        # spikes across RANKs to occur.
        # NOTE: Should this depend on the minimum delay in the network?
        self.pc.set_maxstep(10)



        # create list of cells across all populations to simplify loops
        cells = []
        for name in self.population_names:
            cells += self.populations[name].cells

        # load spike times from NetCon, only needed if LFPy.Synapse class
        # is used
        for cell in cells:
            cell._load_spikes()

        # define data type for structured arrays dependent on the boolean
        # arguments
        dtype = [('imem', float)]
        if use_ipas:
            dtype += [('ipas', float)]
        if use_icap:
            dtype += [('icap', float)]
        if use_isyn:
            dtype += [('isyn_e', float), ('isyn_i', float)]
        if rec_pop_contributions:
            dtype += list(zip(self.population_names,
                              [float] * len(self.population_names)))

        # setup list of structured arrays for all extracellular potentials
        # at each contact from different source terms and subpopulations
        if to_memory:
            for probe, M in zip(probes, transforms):
                probe.data = np.zeros((M.shape[0],
                                       int(mini_step_time / self.dt) + 1),
                                      dtype=dtype)

        # signals for each probe will be stored here during simulations
        if to_file:
            # ensure right ending:
            if file_name.split('.')[-1] != 'h5':
                file_name += '.h5'
            outputfile = h5py.File(
                os.path.join(
                    self.OUTPUTPATH,
                    file_name.format(
                        self._RANK)),
                'w')

            # define unique group names for each probe
            names = []
            for probe, M in zip(probes, transforms):
                name = probe.__class__.__name__
                i = 0
                while True:
                    if name + '{}'.format(i) not in names:
                        names.append(name + '{}'.format(i))
                        break
                    i += 1

            # create groups
            for i, (name, probe, M) in enumerate(zip(names, probes,
                                                     transforms)):
                # can't do it this way until h5py issue #740
                # (https://github.com/h5py/h5py/issues/740) is fixed:
                # outputfile['{}'.format(name)] = np.zeros((M.shape[0],
                #     int(network.tstop / network.dt) + 1), dtype=dtype)
                probe.data = outputfile.create_group('{}'.format(name))
                for key, val in dtype:
                    probe.data[key] = np.zeros((M.shape[0],
                                                int(mini_step_time / self.dt)
                                                + 1),
                                               dtype=val)

        # temporary vector to store membrane currents at each timestep:
        imem = np.zeros(network_dummycell.totnsegs, dtype=dtype)

        def get_imem(imem):
            '''helper function to gather currents across all cells
            on this RANK'''
            i = 0
            totnsegs = 0
            if use_isyn:
                imem['isyn_e'] = 0.  # must reset these for every iteration
                imem['isyn_i'] = 0.  # because we sum over synapses
            for cell in cells:
                for sec in cell.allseclist:
                    for seg in sec:
                        imem['imem'][i] = seg.i_membrane_
                        if use_ipas:
                            imem['ipas'][i] = seg.i_pas
                        if use_icap:
                            imem['icap'][i] = seg.i_cap
                        i += 1

                if use_isyn:
                    for idx, syn in zip(cell.synidx, cell.netconsynapses):
                        if hasattr(syn, 'e') and syn.e > -50:
                            imem['isyn_e'][idx + totnsegs] += syn.i
                        else:
                            imem['isyn_i'][idx + totnsegs] += syn.i

                totnsegs += cell.totnsegs
            return imem

        # run fadvance until time limit, and calculate LFPs for each timestep
        for mini_step in range(0, int(mini_step_time / self.dt)):
        #while neuron.h.t < self.tstop:
            if neuron.h.t >= 0:
                imem = get_imem(imem)

                for j, (probe, M) in enumerate(zip(probes, transforms)):
                    probe.data['imem'][:, tstep] = M @ imem['imem']
                    if use_ipas:
                        probe.data['ipas'][:, tstep] = \
                            M @ (imem['ipas'] * network_dummycell.area * 1E-2)
                    if use_icap:
                        probe.data['icap'][:, tstep] = \
                            M @ (imem['icap'] * network_dummycell.area * 1E-2)
                    if use_isyn:
                        probe.data['isyn_e'][:, tstep] = M @ imem['isyn_e']
                        probe.data['isyn_i'][:, tstep] = M @ imem['isyn_i']

                if rec_pop_contributions:
                    for j, (probe, M) in enumerate(zip(probes, transforms)):
                        k = 0  # counter
                        for nsegs, pop_name in zip(population_nsegs,
                                                   self.population_names):
                            cellinds = np.arange(k, k + nsegs)
                            probe.data[pop_name][:, tstep] = \
                                M[:, cellinds] @ imem['imem'][cellinds, ]
                            k += nsegs

                tstep += 1
            neuron.h.fadvance()
            if neuron.h.t % 100. == 0.:
                if self._RANK == 0:
                    print('t = {} ms'.format(neuron.h.t))

        try:
            # calculate LFP after final fadvance(), skipped if IndexError is
            # encountered
            imem = get_imem(imem)

            for j, (probe, M) in enumerate(zip(probes, transforms)):
                probe.data['imem'][:, tstep] = M @ imem['imem']
                if use_ipas:
                    probe.data['ipas'][:, tstep] = \
                        M @ (imem['ipas'] * network_dummycell.area * 1E-2)
                if use_icap:
                    probe.data['icap'][:, tstep] = \
                        M @ (imem['icap'] * network_dummycell.area * 1E-2)
                if use_isyn:
                    probe.data['isyn_e'][:, tstep] = M @ imem['isyn_e']
                    probe.data['isyn_i'][:, tstep] = M @ imem['isyn_i']

            if rec_pop_contributions:
                for j, (probe, M) in enumerate(zip(probes, transforms)):
                    k = 0  # counter
                    for nsegs, pop_name in zip(population_nsegs,
                                               self.population_names):
                        cellinds = np.arange(k, k + nsegs)
                        probe.data[pop_name][:, tstep] = \
                            M[:, cellinds] @ imem['imem'][cellinds, ]
                        k += nsegs
        except IndexError:
            pass

        if to_file:
            outputfile.close()

        #### Remaining in the simulate function
        # for name in self.population_names:
        #     for cell in self.populations[name].cells:
        #         # somatic trace
        #         cell.somav = np.array(cell.somav)
        #         if rec_imem:
        #             cell._calc_imem()
        #         if rec_ipas:
        #             cell._calc_ipas()
        #         if rec_icap:
        #             cell._calc_icap()
        #         if rec_vmem:
        #             cell._collect_vmem()
        #         if rec_isyn:
        #             cell._collect_isyn()
        #         if rec_vmemsyn:
        #             cell._collect_vsyn()
        #         if rec_istim:
        #             cell._collect_istim()
        #         if len(rec_variables) > 0:
        #             cell._collect_rec_variables(rec_variables)
        #         if hasattr(cell, '_hoc_netstimlist'):
        #             del cell._hoc_netstimlist
        #
        # Collect spike trains across all RANKs to RANK 0
        for name in self.population_names:
            population = self.populations[name]
            population.spike_vectors = []
            for i in range(len(population._hoc_spike_vectors)):
                population.spike_vectors += \
                    [population._hoc_spike_vectors[i].as_numpy()]

        # collect spike times to RANK 0
        if self._RANK == 0:
            times = []
            gids = []
        else:
            times = None
            gids = None
        for i, name in enumerate(self.population_names):
            times_send = [x for x in self.populations[name].spike_vectors]
            gids_send = [x for x in self.populations[name].gids]
            if self._RANK == 0:
                times.append([])
                gids.append([])
                times[i] += flattenlist(self.pc.py_gather(times_send))
                gids[i] += flattenlist(self.pc.py_gather(gids_send))

                assert len(times[-1]) == len(gids[-1])
            else:
                _ = self.pc.py_gather(times_send)
                _ = self.pc.py_gather(gids_send)

        # create final output file, summing up single RANK output from
        # temporary files
        # if to_file and probes is not None:
        #     # op = MPI.SUM
        #     fname = os.path.join(
        #         self.OUTPUTPATH,
        #         'tmp_output_RANK_{:03d}.h5'.format(
        #             self._RANK))
        #     f0 = h5py.File(fname, 'r')
        #     if self._RANK == 0:
        #         f1 = h5py.File(os.path.join(self.OUTPUTPATH, file_name), 'w')
        #     dtype = []
        #     for key, value in f0[list(f0.keys())[0]].items():
        #         dtype.append((str(key), float))
        #     for grp in f0.keys():
        #         if self._RANK == 0:
        #             # get shape from the first dataset
        #             # (they should all be equal):
        #             for value in f0[grp].values():
        #                 shape = value.shape
        #                 continue
        #             f1[grp] = np.zeros(shape, dtype=dtype)
        #         for key, value in f0[grp].items():
        #             recvbuf = neuron.h.Vector(
        #                 value[()].astype(float).flatten())
        #             self.pc.allreduce(recvbuf, 1)
        #             if self._RANK == 0:
        #                 f1[grp][key] = np.array(recvbuf).reshape(value.shape)
        #             else:
        #                 recvbuf = None
        #     f0.close()
        #     if self._RANK == 0:
        #         f1.close()
        #     os.remove(fname)
        #
        # if probes is not None:
        #     if to_memory:
        #         # communicate and sum up measurements on each probe before
        #         # returing spike times and corresponding gids:
        #         for probe in probes:
        #             probe.data = ReduceStructArray(probe.data)

        return dict(times=times, gids=gids), neuron.h.t

    def step_without_probes(self, probes=None,rec_imem= False,rec_vmem= False,rec_ipas= False,rec_icap= False,
                                    rec_isyn= False,
                                       rec_vmemsyn= False,
                                       rec_istim= False,
                                    rec_current_dipole_moment=False,
                                    rec_variables= [],
                                    dotprodcoeffs= None,
                                     to_memory=True,
                                     to_file=False,
                                     file_name=None,
                                     use_ipas=False, use_icap=False,
                                     use_isyn=False,
                                     rec_pop_contributions=False
                                     ):


        tstep = 0
        mini_step_time = self.obs_win_len

        # set maximum integration step, it is necessary for communication of
        # spikes across RANKs to occur.
        # NOTE: Should this depend on the minimum delay in the network?
        self.pc.set_maxstep(10)

        # create list of cells across all populations to simplify loops
        cells = []
        for name in self.population_names:
            cells += self.populations[name].cells

        # load spike times from NetCon, only needed if LFPy.Synapse class
        # is used
        for cell in cells:
            cell._load_spikes()

        # define data type for structured arrays dependent on the boolean
        # arguments
        dtype = [('imem', float)]
        if use_ipas:
            dtype += [('ipas', float)]
        if use_icap:
            dtype += [('icap', float)]
        if use_isyn:
            dtype += [('isyn_e', float), ('isyn_i', float)]
        if rec_pop_contributions:
            dtype += list(zip(self.population_names,
                              [float] * len(self.population_names)))

        # run fadvance until time limit, and calculate LFPs for each timestep
        for mini_step in range(0, int(mini_step_time / self.dt)):
            if neuron.h.t >= 0:
                tstep += 1
            neuron.h.fadvance()
            if neuron.h.t % 100. == 0.:
                if self._RANK == 0:
                    print('t = {} ms'.format(neuron.h.t))

        #
        # Collect spike trains across all RANKs to RANK 0
        for name in self.population_names:
            population = self.populations[name]
            population.spike_vectors = []
            for i in range(len(population._hoc_spike_vectors)):
                population.spike_vectors += \
                    [population._hoc_spike_vectors[i].as_numpy()]

        # collect spike times to RANK 0
        if self._RANK == 0:
            times = []
            gids = []
        else:
            times = None
            gids = None
        for i, name in enumerate(self.population_names):
            times_send = [x for x in self.populations[name].spike_vectors]
            gids_send = [x for x in self.populations[name].gids]
            if self._RANK == 0:
                times.append([])
                gids.append([])
                times[i] += flattenlist(self.pc.py_gather(times_send))
                gids[i] += flattenlist(self.pc.py_gather(gids_send))

                assert len(times[-1]) == len(gids[-1])
            else:
                _ = self.pc.py_gather(times_send)
                _ = self.pc.py_gather(gids_send)

        return dict(times=times, gids=gids), neuron.h.t

    def _step(self, probes=None, variable_dt=False, atol=0.001,
                rtol=0., to_memory=True,
                to_file=False,
                file_name=None,
                use_ipas=False, use_icap=True,
                use_isyn=True,
                rec_pop_contributions=False,rec_imem=False, rec_vmem=False,
                 rec_ipas=False, rec_icap=False,
                 rec_isyn=False, rec_vmemsyn=False, rec_istim=False,
                 rec_variables=[], ):

        tstep = 0
        mini_step_time = 100

        if to_memory and to_file:
            raise Exception('to_memory and to_file can not both be True')
        if to_file and file_name is None:
            raise Exception
        # create a dummycell object lumping together needed attributes
        # for calculation of extracellular potentials etc. The population_nsegs
        # array is used to slice indices such that single-population
        # contributions to the potential can be calculated.
        population_nsegs, network_dummycell = self.__create_network_dummycell()

        # set cell attribute on each probe, assuming that each probe was
        # instantiated with argument cell=None
        for probe in probes:
            if probe.cell is None:
                probe.cell = network_dummycell
            else:
                raise Exception('{}.cell!=None'.format(probe.__class__))

        # create list of transformation matrices; one for each probe
        transforms = []
        if probes is not None:
            for probe in probes:
                transforms.append(probe.get_transformation_matrix())

        # reset probe.cell to None, as it is no longer needed
        for probe in probes:
            probe.cell = None

        ################ create list of cells across all populations to simplify loops
        cells = []
        for name in self.population_names:
            cells += self.populations[name].cells

        # load spike times from NetCon, only needed if LFPy.Synapse class
        # is used
        for cell in cells:
            cell._load_spikes()
        ###########################

        # define data type for structured arrays dependent on the boolean
        # arguments
        dtype = [('imem', float)]
        if use_ipas:
            dtype += [('ipas', float)]
        if use_icap:
            dtype += [('icap', float)]
        if use_isyn:
            dtype += [('isyn_e', float), ('isyn_i', float)]
        if rec_pop_contributions:
            dtype += list(zip(self.population_names,
                              [float] * len(self.population_names)))

        # setup list of structured arrays for all extracellular potentials
        # at each contact from different source terms and subpopulations
        if to_memory:
            for probe, M in zip(probes, transforms):
                probe.data = np.zeros((M.shape[0],
                                       int(mini_step_time / self.dt) + 1),
                                      dtype=dtype)

        # signals for each probe will be stored here during simulations
        if to_file:
            # ensure right ending:
            if file_name.split('.')[-1] != 'h5':
                file_name += '.h5'
            outputfile = h5py.File(
                os.path.join(
                    self.OUTPUTPATH,
                    file_name.format(
                        self._RANK)),
                'w')

            # define unique group names for each probe
            names = []
            for probe, M in zip(probes, transforms):
                name = probe.__class__.__name__
                i = 0
                while True:
                    if name + '{}'.format(i) not in names:
                        names.append(name + '{}'.format(i))
                        break
                    i += 1

            # create groups
            for i, (name, probe, M) in enumerate(zip(names, probes,
                                                     transforms)):
                # can't do it this way until h5py issue #740
                # (https://github.com/h5py/h5py/issues/740) is fixed:
                # outputfile['{}'.format(name)] = np.zeros((M.shape[0],
                #     int(network.tstop / network.dt) + 1), dtype=dtype)
                probe.data = outputfile.create_group('{}'.format(name))
                for key, val in dtype:
                    probe.data[key] = np.zeros((M.shape[0],
                                                int(mini_step_time/ self.dt)
                                                + 1),
                                               dtype=val)

        # temporary vector to store membrane currents at each timestep:
        imem = np.zeros(network_dummycell.totnsegs, dtype=dtype)

        def get_imem(imem):
            '''helper function to gather currents across all cells
            on this RANK'''
            i = 0
            totnsegs = 0
            if use_isyn:
                imem['isyn_e'] = 0.  # must reset these for every iteration
                imem['isyn_i'] = 0.  # because we sum over synapses
            for cell in cells:
                for sec in cell.allseclist:
                    for seg in sec:
                        imem['imem'][i] = seg.i_membrane_
                        if use_ipas:
                            imem['ipas'][i] = seg.i_pas
                        if use_icap:
                            imem['icap'][i] = seg.i_cap
                        i += 1

                if use_isyn:
                    for idx, syn in zip(cell.synidx, cell.netconsynapses):
                        if hasattr(syn, 'e') and syn.e > -50:
                            imem['isyn_e'][idx + totnsegs] += syn.i
                        else:
                            imem['isyn_i'][idx + totnsegs] += syn.i

                totnsegs += cell.totnsegs
            return imem

        # run fadvance until time limit, and calculate LFPs for each timestep


        #while neuron.h.t < self.tstop:
        for mini_step in range(0, int(mini_step_time / self.dt)):
            if neuron.h.t >= 0:
                imem = get_imem(imem)

                for j, (probe, M) in enumerate(zip(probes, transforms)):
                    probe.data['imem'][:, tstep] = M @ imem['imem']
                    if use_ipas:
                        probe.data['ipas'][:, tstep] = \
                            M @ (imem['ipas'] * network_dummycell.area * 1E-2)
                    if use_icap:
                        probe.data['icap'][:, tstep] = \
                            M @ (imem['icap'] * network_dummycell.area * 1E-2)
                    if use_isyn:
                        probe.data['isyn_e'][:, tstep] = M @ imem['isyn_e']
                        probe.data['isyn_i'][:, tstep] = M @ imem['isyn_i']

                if rec_pop_contributions:
                    for j, (probe, M) in enumerate(zip(probes, transforms)):
                        k = 0  # counter
                        for nsegs, pop_name in zip(population_nsegs,
                                                   self.population_names):
                            cellinds = np.arange(k, k + nsegs)
                            probe.data[pop_name][:, tstep] = \
                                M[:, cellinds] @ imem['imem'][cellinds, ]
                            k += nsegs

                tstep += 1
            neuron.h.fadvance()
            #print("Step taken at t = {}, point process current".format(list(self._neuron_tvec)[-1]))
            if neuron.h.t % 100. == 0.:
                if self._RANK == 0:
                    print('t = {} ms'.format(neuron.h.t))

        try:
            print("calculating LFPy")
            print("number of steps {}".format(tstep))
            # calculate LFP after final fadvance(), skipped if IndexError is
            # encountered
            imem = get_imem(imem)

            for j, (probe, M) in enumerate(zip(probes, transforms)):
                probe.data['imem'][:, tstep] = M @ imem['imem']
                if use_ipas:
                    probe.data['ipas'][:, tstep] = \
                        M @ (imem['ipas'] * network_dummycell.area * 1E-2)
                if use_icap:
                    probe.data['icap'][:, tstep] = \
                        M @ (imem['icap'] * network_dummycell.area * 1E-2)
                if use_isyn:
                    probe.data['isyn_e'][:, tstep] = M @ imem['isyn_e']
                    probe.data['isyn_i'][:, tstep] = M @ imem['isyn_i']

            if rec_pop_contributions:
                for j, (probe, M) in enumerate(zip(probes, transforms)):
                    k = 0  # counter
                    for nsegs, pop_name in zip(population_nsegs,
                                               self.population_names):
                        cellinds = np.arange(k, k + nsegs)
                        probe.data[pop_name][:, tstep] = \
                            M[:, cellinds] @ imem['imem'][cellinds, ]
                        k += nsegs
        except IndexError:
            pass

        # #### Remaining in the simulate function
        # for name in self.population_names:
        #     for cell in self.populations[name].cells:
        #         # somatic trace
        #         cell.somav = np.array(cell.somav)
        #         if rec_imem:
        #             cell._calc_imem()
        #         if rec_ipas:
        #             cell._calc_ipas()
        #         if rec_icap:
        #             cell._calc_icap()
        #         if rec_vmem:
        #             cell._collect_vmem()
        #         if rec_isyn:
        #             cell._collect_isyn()
        #         if rec_vmemsyn:
        #             cell._collect_vsyn()
        #         if rec_istim:
        #             cell._collect_istim()
        #         if len(rec_variables) > 0:
        #             cell._collect_rec_variables(rec_variables)
        #         if hasattr(cell, '_hoc_netstimlist'):
        #             del cell._hoc_netstimlist
        #
        # # Collect spike trains across all RANKs to RANK 0
        # for name in self.population_names:
        #     population = self.populations[name]
        #     population.spike_vectors = []
        #     for i in range(len(population._hoc_spike_vectors)):
        #         population.spike_vectors += \
        #             [population._hoc_spike_vectors[i].as_numpy()]
        #
        # # collect spike times to RANK 0
        # if self._RANK == 0:
        #     times = []
        #     gids = []
        # else:
        #     times = None
        #     gids = None
        # for i, name in enumerate(self.population_names):
        #     times_send = [x for x in self.populations[name].spike_vectors]
        #     gids_send = [x for x in self.populations[name].gids]
        #     if self._RANK == 0:
        #         times.append([])
        #         gids.append([])
        #         times[i] += flattenlist(self.pc.py_gather(times_send))
        #         gids[i] += flattenlist(self.pc.py_gather(gids_send))
        #
        #         assert len(times[-1]) == len(gids[-1])
        #     else:
        #         _ = self.pc.py_gather(times_send)
        #         _ = self.pc.py_gather(gids_send)
        #
        # # create final output file, summing up single RANK output from
        # # temporary files
        # if to_file and probes is not None:
        #     # op = MPI.SUM
        #     fname = os.path.join(
        #         self.OUTPUTPATH,
        #         'tmp_output_RANK_{:03d}.h5'.format(
        #             self._RANK))
        #     f0 = h5py.File(fname, 'r')
        #     if self._RANK == 0:
        #         f1 = h5py.File(os.path.join(self.OUTPUTPATH, file_name), 'w')
        #     dtype = []
        #     for key, value in f0[list(f0.keys())[0]].items():
        #         dtype.append((str(key), float))
        #     for grp in f0.keys():
        #         if self._RANK == 0:
        #             # get shape from the first dataset
        #             # (they should all be equal):
        #             for value in f0[grp].values():
        #                 shape = value.shape
        #                 continue
        #             f1[grp] = np.zeros(shape, dtype=dtype)
        #         for key, value in f0[grp].items():
        #             recvbuf = neuron.h.Vector(
        #                 value[()].astype(float).flatten())
        #             self.pc.allreduce(recvbuf, 1)
        #             if self._RANK == 0:
        #                 f1[grp][key] = np.array(recvbuf).reshape(value.shape)
        #             else:
        #                 recvbuf = None
        #     f0.close()
        #     if self._RANK == 0:
        #         f1.close()
        #     os.remove(fname)
        #
        # if probes is not None:
        #     if to_memory:
        #         # communicate and sum up measurements on each probe before
        #         # returing spike times and corresponding gids:
        #         for probe in probes:
        #             probe.data = ReduceStructArray(probe.data)
        #
        # return dict(times=times, gids=gids)

    def enable_extracellular_stimulation_mpi(self, electrode, t_ext=None, n=1,
                                         model='inf'):
        """
        Enable extracellular stimulation with NEURON's `extracellular`
        mechanism. Extracellular potentials are computed from electrode
        currents using the point-source approximation.
        If ``model`` is ``'inf'`` (default), potentials are computed as
        (:math:`r_i` is the position of a segment :math:`i`,
        :math:`r_n` is the position of an electrode :math:`n`,
        :math:`\\sigma` is the conductivity of the medium):

        .. math::
            V_e(r_i) = \\sum_n \\frac{I_n}{4 \\pi \\sigma |r_i - r_n|}

        If ``model`` is ``'semi'``, the method of images is used:

        .. math::
            V_e(r_i) = \\sum_n \\frac{I_n}{2 \\pi \\sigma |r_i - r_n|}

        Parameters
        ----------
        electrode: RecExtElectrode
            Electrode object with stimulating currents
        t_ext: np.ndarray or list
            Time in ms corresponding to step changes in the provided currents.
            If None, currents are assumed to have
            the same time steps as the NEURON simulation.
        n: int
            Points per electrode for spatial averaging
        model: str
            ``'inf'`` or ``'semi'``. If ``'inf'`` the medium is assumed to be
            infinite and homogeneous. If ``'semi'``, the method of
            images is used.

        Returns
        -------
        v_ext: dict of np.ndarrays
            Computed extracellular potentials at cell mid points
            for each cell of the network's populations. Formatted as
            ``v_ext = {'pop1': np.ndarray[cell, cell_seg,t_ext]}``
        """
        v_ext = {}
        for popname in self.populations.keys():
            cells = self.populations[popname].cells
            if len(cells) != 0:  # TODO: <chirath> I'm skipping when cells are zero during multiple processes.
                v_ext[popname] = np.zeros(
                    (len(cells), cells[0].totnsegs, len(t_ext)))

                for id_cell, cell in enumerate(cells):
                    v_ext[popname][id_cell] = \
                        cell.enable_extracellular_stimulation(
                            electrode, t_ext, n, model)

        return v_ext
